{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Laboratorio de Amazon Transcribe y Amazon Comprehend\n",
    "\n",
    "En este laboratorio veremos como utilizar Amazon Transcribe para obtener una transcripción de un archivo de audio como puede ser un podcast, una conversación en un contact center o un video, del cual queremos extraer la conversación. Después de hacer esta extracción utilizaremos Amazon Comprehend para analizar la extracción de texto y obtener más información sobre la transcripción.\n",
    "\n",
    "Para comenzar es necesario escribir el nombre del bucket de S3 que estaremos utilizando en el laboratorio así como el nombre del rol, estos los podemos localizar en la sección de Salidas (Outputs) de [CloudFormation]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import boto3\n",
    "import gzip\n",
    "import io\n",
    "import requests\n",
    "import time\n",
    "import tarfile\n",
    "import uuid\n",
    "\n",
    "bucket_name = 'CHANGE_ME'\n",
    "comprehend_role_arn = 'CHANGE_ME'\n",
    "comprehend = boto3.client('comprehend')\n",
    "transcribe = boto3.client('transcribe')\n",
    "s3 = boto3.client('s3')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Amazon Transcribe\n",
    "\n",
    "Comenzaremos extrayendo la conversación de un archivo de texto, en este caso utilizaremos un podcast de AWS en español.\n",
    "\n",
    "*Tip: Para experimentar puedes sustituir la URL del código apuntando a otro archivo de audio.*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "media_format = 'mp3'\n",
    "content_type = 'audio/mpeg3'\n",
    "t_job_name = str(uuid.uuid4())\n",
    "key = 'audio/' + t_job_name + '.' + media_format\n",
    "audio_url = 'https://d3h2ozso0dirfl.cloudfront.net/episodes/EP48-Technical-Containers-1.mp3'\n",
    "audio_bytes = requests.get(audio_url, allow_redirects=True).content\n",
    "r_put_object = s3.put_object(Body=audio_bytes, Bucket=bucket_name, ContentLength=len(audio_bytes),\n",
    "                             ContentType=content_type, Key=key)\n",
    "media_s3_uri = 's3://' + bucket_name + '/' + key"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora iniciaremos la ejecución del proceso de transcripción."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_output_key = 'transcripts/' + t_job_name\n",
    "t_response = transcribe.start_transcription_job(TranscriptionJobName=t_job_name,\n",
    "                                                Media={'MediaFileUri': media_s3_uri},\n",
    "                                                MediaFormat=media_format,\n",
    "                                                OutputBucketName=bucket_name,\n",
    "                                                OutputKey=t_output_key,\n",
    "                                                IdentifyLanguage=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La transcripción es un proceso asíncrono, por lo que es necesario realizar consultas periódicas o diseñar el flujo para continuar con eventos."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "while True:\n",
    "    r_status = transcribe.get_transcription_job(TranscriptionJobName=t_job_name)\n",
    "    if 'TranscriptionJob' in r_status and 'TranscriptionJobStatus' in r_status['TranscriptionJob']:\n",
    "        status = r_status['TranscriptionJob']['TranscriptionJobStatus']\n",
    "        if status == 'COMPLETED' or status == 'FAILED':\n",
    "            print(status)\n",
    "            break\n",
    "        else:\n",
    "            print(status)\n",
    "            time.sleep(30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora que la transcripción está finalizada podemos recuperarla con las llaves que proporcionamos al servicio al iniciar el proceso. Unimos las diferentes transcripciones y subimos un archivo de texto al servicio de S3. En esta sección podemos ver los limites del servicio [Comprehend Quotas](https://docs.aws.amazon.com/comprehend/latest/dg/guidelines-and-limits.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "r_get_object = s3.get_object(Bucket=bucket_name, Key=t_output_key)\n",
    "transcription = json.load(r_get_object['Body'])\n",
    "text = ''\n",
    "if 'results' in transcription:\n",
    "    for transcript in transcription['results']['transcripts']:\n",
    "        text += transcript['transcript']\n",
    "\n",
    "text_bytes = bytearray(text, 'utf-8')\n",
    "text_key = 'text/' + t_job_name + '.txt'\n",
    "r_put_object = s3.put_object(Body=text_bytes, Bucket=bucket_name, ContentLength=len(text_bytes),\n",
    "                             ContentType='text/plain', Key=text_key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora analizaremos el texto con el servicio de Amazon Comprehend. Para evitar llegar al límite de 5000 bytes utilizaremos las funciones asíncronas.\n",
    "Primero utilizaremos la detección de entidades."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "entities_key = 'comprehend/entities/' + t_job_name\n",
    "key_phrases_key = 'comprehend/phrases/' + t_job_name\n",
    "sentiment_key = 'comprehend/sentiment/' + t_job_name\n",
    "topics_key = 'comprehend/topics/' + t_job_name\n",
    "\n",
    "comprehend_role_arn = 'arn:aws:iam::253323635394:role/ComprehendIDRole'\n",
    "entities_r = comprehend.start_entities_detection_job(\n",
    "    InputDataConfig={\n",
    "        'S3Uri': 's3://' + bucket_name + '/' + text_key,\n",
    "        'InputFormat': 'ONE_DOC_PER_FILE'\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': 's3://' + bucket_name + '/' + entities_key\n",
    "    },\n",
    "    JobName=t_job_name + 'Entities',\n",
    "    LanguageCode='es',\n",
    "    DataAccessRoleArn=comprehend_role_arn\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora buscaremos las frases clave dentro del document."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "key_phrases_r = comprehend.start_key_phrases_detection_job(\n",
    "    InputDataConfig={\n",
    "        'S3Uri': 's3://' + bucket_name + '/' + text_key,\n",
    "        'InputFormat': 'ONE_DOC_PER_FILE'\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': 's3://' + bucket_name + '/' + key_phrases_key\n",
    "    },\n",
    "    JobName=t_job_name + 'KeyPhrases',\n",
    "    LanguageCode='es',\n",
    "    DataAccessRoleArn=comprehend_role_arn\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora ejecutaremos la detección de sentimiento (esta función requiere un tamaño máximo de 5120 bytes, por lo que es muy probable que falle con textos grandes)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentiment_r = comprehend.start_sentiment_detection_job(\n",
    "    InputDataConfig={\n",
    "        'S3Uri': 's3://' + bucket_name + '/' + text_key,\n",
    "        'InputFormat': 'ONE_DOC_PER_FILE'\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': 's3://' + bucket_name + '/' + sentiment_key\n",
    "    },\n",
    "    JobName=t_job_name + 'Sentiment',\n",
    "    LanguageCode='es',\n",
    "    DataAccessRoleArn=comprehend_role_arn\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora ejecutaremos la detección de tópicos."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topics_r = comprehend.start_topics_detection_job(\n",
    "    InputDataConfig={\n",
    "        'S3Uri': 's3://' + bucket_name + '/' + text_key,\n",
    "        'InputFormat': 'ONE_DOC_PER_FILE'\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': 's3://' + bucket_name + '/' + topics_key\n",
    "    },\n",
    "    JobName=t_job_name + 'Topics',\n",
    "    DataAccessRoleArn=comprehend_role_arn\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora esperemos a que Comprehend termine las tareas asignadas. Si encontramos algún fallo (FAILED), podemos revisarlo a detalle en la consola de [Amazon Comprehend](https://console.aws.amazon.com/comprehend)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "entities_job = None\n",
    "key_phrases_job = None\n",
    "sentiment_job = None\n",
    "topics_job = None\n",
    "\n",
    "while True:\n",
    "    response = comprehend.describe_entities_detection_job(JobId=entities_r['JobId'])\n",
    "    if 'EntitiesDetectionJobProperties' in response and 'JobStatus' in response['EntitiesDetectionJobProperties']:\n",
    "        status = response['EntitiesDetectionJobProperties']['JobStatus']\n",
    "        print(status)\n",
    "        if status == 'COMPLETED' or status == 'FAILED':\n",
    "            entities_job = response['EntitiesDetectionJobProperties']\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(30)\n",
    "\n",
    "while True:\n",
    "    response = comprehend.describe_key_phrases_detection_job(JobId=key_phrases_r['JobId'])\n",
    "    if 'KeyPhrasesDetectionJobProperties' in response and 'JobStatus' in response['KeyPhrasesDetectionJobProperties']:\n",
    "        status = response['KeyPhrasesDetectionJobProperties']['JobStatus']\n",
    "        print(status)\n",
    "        if status == 'COMPLETED' or status == 'FAILED':\n",
    "            key_phrases_job = response['KeyPhrasesDetectionJobProperties']\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(30)\n",
    "\n",
    "while True:\n",
    "    response = comprehend.describe_sentiment_detection_job(JobId=sentiment_r['JobId'])\n",
    "    if 'SentimentDetectionJobProperties' in response and 'JobStatus' in response['SentimentDetectionJobProperties']:\n",
    "        status = response['SentimentDetectionJobProperties']['JobStatus']\n",
    "        print(status)\n",
    "        if status == 'COMPLETED' or status == 'FAILED':\n",
    "            sentiment_job = response['SentimentDetectionJobProperties']\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(30)\n",
    "\n",
    "while True:\n",
    "    response = comprehend.describe_topics_detection_job(JobId=topics_r['JobId'])\n",
    "    if 'TopicsDetectionJobProperties' in response and 'JobStatus' in response['TopicsDetectionJobProperties']:\n",
    "        status = response['TopicsDetectionJobProperties']['JobStatus']\n",
    "        print(status)\n",
    "        if status == 'COMPLETED' or status == 'FAILED':\n",
    "            topics_job = response['TopicsDetectionJobProperties']\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comencemos analizando la respuesta de detección de entidades"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if entities_job and entities_job['JobStatus'] == 'COMPLETED':\n",
    "    output_key = entities_job['OutputDataConfig']['S3Uri'][6 + len(bucket_name):]\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=output_key)\n",
    "    tar_file = gzip.GzipFile(fileobj=io.BytesIO(response['Body'].read()))\n",
    "    tar = tarfile.open(fileobj=tar_file, mode='r:')\n",
    "    content = tar.extractfile(tar.getmembers()[0])\n",
    "    entities = json.loads(content.read())\n",
    "    max_entities = 10 # Cambiar para mostrar más\n",
    "    for entity in entities['Entities']:\n",
    "        if entity['Score'] >= 0.8 and max_entities >= 0:\n",
    "            print('Texto: {} Tipo: {}'.format(entity['Text'], entity['Type']))\n",
    "            max_entities -= 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora analicemos la respuesta de detección de frases clave"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if key_phrases_job and key_phrases_job['JobStatus'] == 'COMPLETED':\n",
    "    output_key = key_phrases_job['OutputDataConfig']['S3Uri'][6 + len(bucket_name):]\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=output_key)\n",
    "    tar_file = gzip.GzipFile(fileobj=io.BytesIO(response['Body'].read()))\n",
    "    tar = tarfile.open(fileobj=tar_file, mode='r:')\n",
    "    content = tar.extractfile(tar.getmembers()[0])\n",
    "    key_phrases = json.loads(content.read())['KeyPhrases']\n",
    "    max_phrases = 10 # Cambiar para mostrar más\n",
    "    print(key_phrases)\n",
    "    for phrase in key_phrases:\n",
    "        if phrase['Score'] >= 0.8 and max_phrases >= 0:\n",
    "            print('Texto: {}'.format(phrase['Text']))\n",
    "            max_phrases -= 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora verifiquemos la respuesta de detección de sentimiento"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if sentiment_job and sentiment_job['JobStatus'] == 'COMPLETED':\n",
    "    output_key = sentiment_job['OutputDataConfig']['S3Uri'][6 + len(bucket_name):]\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=output_key)\n",
    "    tar_file = gzip.GzipFile(fileobj=io.BytesIO(response['Body'].read()))\n",
    "    tar = tarfile.open(fileobj=tar_file, mode='r:')\n",
    "    content = tar.extractfile(tar.getmembers()[0])\n",
    "    key_phrases = json.loads(content.read())['KeyPhrases']\n",
    "    max_phrases = 10 # Cambiar para mostrar más\n",
    "    print(key_phrases)\n",
    "    for phrase in key_phrases:\n",
    "        if phrase['Score'] >= 0.8 and max_phrases >= 0:\n",
    "            print('Texto: {}'.format(phrase['Text']))\n",
    "            max_phrases -= 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente analicemos la respuesta de detección de tópicos, esta respuesta son archivos CSV."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if topics_job and topics_job['JobStatus'] == 'COMPLETED':\n",
    "    output_key = topics_job['OutputDataConfig']['S3Uri'][6 + len(bucket_name):]\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=output_key)\n",
    "    tar_file = gzip.GzipFile(fileobj=io.BytesIO(response['Body'].read()))\n",
    "    tar = tarfile.open(fileobj=tar_file, mode='r:')\n",
    "    for member in tar.getmembers():\n",
    "        print(member.name)\n",
    "        print(str(tar.extractfile(member).read(), 'utf-8'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}