{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Laboratorio de Amazon Rekognition\n",
    "\n",
    "En este laboratorio exploraremos las siguientes capacidades de Rekognition.\n",
    "\n",
    "- Detección de Objetos y Escenas en imágenes.\n",
    "- Análisis Facial\n",
    "- Comparación de rostros\n",
    "- Detección de equipo protector\n",
    "\n",
    "*Tip: Durante los laboratorios es posible cambiar las URLs de las imagenes para experimentar con otros archivos.*"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Detección de Objetos y Escenas\n",
    "\n",
    "En esta sección tomaremos diferentes imágenes y las analizaremos utilizando el servicio de Rekognition.\n",
    "\n",
    "Empezaremos por importar las librerías necesarias para la manipulación de imágenes y el cliente para utilizar Rekognition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import boto3\n",
    "import requests\n",
    "import io\n",
    "from IPython.display import Image, display\n",
    "from PIL import Image as PImage, ImageDraw, ImageFont\n",
    "\n",
    "# Se obtiene el cliente de Rekognition.\n",
    "rekognition = boto3.client('rekognition')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esta función nos servirá para crear rectángulos al rededor de los objetos detectados."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def box_labels(image_bytes, labels, confidence):\n",
    "    font = ImageFont.load_default()\n",
    "    image = PImage.open(io.BytesIO(image_bytes))\n",
    "    width, height = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for label in labels:\n",
    "        name = label['Name']\n",
    "        if label['Confidence'] >= confidence:\n",
    "            for instance in label['Instances']:\n",
    "                if instance['Confidence'] >= confidence and 'BoundingBox' in instance:\n",
    "                    start_x = instance['BoundingBox']['Left'] * width\n",
    "                    start_y = instance['BoundingBox']['Top'] * height\n",
    "                    end_x = start_x + instance['BoundingBox']['Width'] * width\n",
    "                    end_y = start_y + instance['BoundingBox']['Height'] * height\n",
    "                    draw.rectangle([(start_x, start_y), (end_x, end_y)], outline='black', width=2)\n",
    "                    draw.text((start_x + 5, start_y + 5), name, fill='black', font=font)\n",
    "    image_out = io.BytesIO()\n",
    "    image.save(image_out, 'JPEG')\n",
    "    return image_out.getvalue()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuación descargaremos las imágenes que serán utilizadas para detectar objetos y para detectar la escena."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "objects_url = 'https://dhei5unw3vrsx.cloudfront.net/images/skateboard_resized.jpg'\n",
    "scene_url = 'https://dhei5unw3vrsx.cloudfront.net/images/landscape_resized.jpg'\n",
    "objects_response = requests.get(objects_url, allow_redirects=True)\n",
    "scene_response = requests.get(scene_url, allow_redirects=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora que contamos con las imágenes a analizar comencemos con la detección de objetos."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "objects_image = objects_response.content\n",
    "display(Image(data=objects_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generamos la petición de análisis a Rekognition y utilizamos nuestra función para marcar las etiquetas detectadas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "objects_a = rekognition.detect_labels(Image={\n",
    "    'Bytes': objects_image\n",
    "})\n",
    "## Set a high confidence to reduce number of boxes.\n",
    "new_objects_image = box_labels(objects_image, objects_a['Labels'], 90.0)\n",
    "display(Image(data=new_objects_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora analizaremos el contexto de una imagen."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scene_image = scene_response.content\n",
    "display(Image(data=scene_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "objects_a = rekognition.detect_labels(Image={\n",
    "    'Bytes': scene_image\n",
    "})\n",
    "confidence = 90.0\n",
    "detected_labels = list()\n",
    "for label in objects_a['Labels']:\n",
    "    if label['Confidence'] >= confidence:\n",
    "        detected_labels.append(label['Name'])\n",
    "print(detected_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Análisis facial\n",
    "\n",
    "Ahora realizaremos un análisis facial."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "single_face_url = 'https://dhei5unw3vrsx.cloudfront.net/images/drive_resized.jpg'\n",
    "multi_face_url = 'https://dhei5unw3vrsx.cloudfront.net/images/family_resized.jpg'\n",
    "single_face_image = requests.get(single_face_url, allow_redirects=True).content\n",
    "multi_face_image = requests.get(multi_face_url, allow_redirects=True).content"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definiremos las siguientes funciones para crear un cuadro donde Rekognition detecto el rostro e imprimir los detalles de cada rostro."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "box_colors = ['red', 'green', 'blue', 'orange', 'yellow', 'black', 'grey', 'purple']\n",
    "\n",
    "def box_face(image_bytes, faces):\n",
    "    image = PImage.open(io.BytesIO(image_bytes))\n",
    "    width, height = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    idx = 0\n",
    "    for face in faces:\n",
    "        if 'BoundingBox' in face:\n",
    "            start_x = face['BoundingBox']['Left'] * width\n",
    "            start_y = face['BoundingBox']['Top'] * height\n",
    "            end_x = start_x + face['BoundingBox']['Width'] * width\n",
    "            end_y = start_y + face['BoundingBox']['Height'] * height\n",
    "            draw.rectangle([(start_x, start_y), (end_x, end_y)], outline=box_colors[idx], width=2)\n",
    "            idx = idx + 1 if idx + 1 < len(box_colors) else 0\n",
    "    image_out = io.BytesIO()\n",
    "    image.save(image_out, 'JPEG')\n",
    "    return image_out.getvalue()\n",
    "\n",
    "def features(faces, confidence):\n",
    "    idx = 0\n",
    "    for face in faces:\n",
    "        print('Box color: ' + box_colors[idx])\n",
    "        print('Age range from {} to {}'.format(face['AgeRange']['Low'], face['AgeRange']['High']))\n",
    "        print('Smiling {} with confidence {}'.format(face['Smile']['Value'], face['Smile']['Confidence']))\n",
    "        print('Smiling {} with confidence {}'.format(face['Eyeglasses']['Value'], face['Eyeglasses']['Confidence']))\n",
    "        print('Smiling {} with confidence {}'.format(face['Sunglasses']['Value'], face['Sunglasses']['Confidence']))\n",
    "        print('Smiling {} with confidence {}'.format(face['Gender']['Value'], face['Gender']['Confidence']))\n",
    "        print('Smiling {} with confidence {}'.format(face['Beard']['Value'], face['Beard']['Confidence']))\n",
    "        print('Smiling {} with confidence {}'.format(face['Mustache']['Value'], face['Mustache']['Confidence']))\n",
    "        print('Smiling {} with confidence {}'.format(face['EyesOpen']['Value'], face['EyesOpen']['Confidence']))\n",
    "        print('Smiling {} with confidence {}'.format(face['MouthOpen']['Value'], face['MouthOpen']['Confidence']))\n",
    "        for emotion in face['Emotions']:\n",
    "            if emotion['Confidence'] >= confidence:\n",
    "                print('The person is {}'.format(emotion['Type']))\n",
    "        print('\\n')\n",
    "        idx = idx + 1 if idx + 1 < len(box_colors) else 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En este primer ejercicio utilizaremos una imagen con un solo rostros para el análisis."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(Image(data=single_face_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "detect_face_r = rekognition.detect_faces(Image={'Bytes': single_face_image}, Attributes=['ALL'])\n",
    "display(Image(data=box_face(single_face_image, detect_face_r['FaceDetails'])))\n",
    "features(detect_face_r['FaceDetails'], 80.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora realicemos el análisis sobre una imagen con diferentes rostros."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(Image(data=multi_face_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "detect_face_r = rekognition.detect_faces(Image={'Bytes': multi_face_image}, Attributes=['ALL'])\n",
    "display(Image(data=box_face(multi_face_image, detect_face_r['FaceDetails'])))\n",
    "features(detect_face_r['FaceDetails'], 80.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparación de Rostros\n",
    "\n",
    "En este laboratorio haremos una comparación de rostros entre dos imágenes con la finalidad de detectar si una persona se encuentra en ambas fotografías."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "source_img_url = 'https://dhei5unw3vrsx.cloudfront.net/images/source3_resized.jpg'\n",
    "target_img_url = 'https://dhei5unw3vrsx.cloudfront.net/images/target3_resized.jpg'\n",
    "source_image = requests.get(source_img_url, allow_redirects=True).content\n",
    "target_image = requests.get(target_img_url, allow_redirects=True).content\n",
    "\n",
    "display(Image(data=source_image))\n",
    "display(Image(data=target_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora realizamos el análisis con Rekognition."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def crop_face(image_bytes, face):\n",
    "    image = PImage.open(io.BytesIO(image_bytes))\n",
    "    width, height = image.size\n",
    "    cropped_bytes = image_bytes\n",
    "    if 'BoundingBox' in face:\n",
    "        start_x = face['BoundingBox']['Left'] * width\n",
    "        start_y = face['BoundingBox']['Top'] * height\n",
    "        end_x = start_x + face['BoundingBox']['Width'] * width\n",
    "        end_y = start_y + face['BoundingBox']['Height'] * height\n",
    "        cropped = image.crop((start_x, start_y, end_x, end_y))\n",
    "        image_out = io.BytesIO()\n",
    "        cropped.save(image_out, 'JPEG')\n",
    "        cropped_bytes = image_out.getvalue()\n",
    "    return cropped_bytes\n",
    "\n",
    "def crop_faces(image_bytes, faces):\n",
    "    cropped_faces = list()\n",
    "    image = PImage.open(io.BytesIO(image_bytes))\n",
    "    width, height = image.size\n",
    "    for face in faces:\n",
    "        if 'Face' in face and 'BoundingBox' in face['Face']:\n",
    "            start_x = face['Face']['BoundingBox']['Left'] * width\n",
    "            start_y = face['Face']['BoundingBox']['Top'] * height\n",
    "            end_x = start_x + face['Face']['BoundingBox']['Width'] * width\n",
    "            end_y = start_y + face['Face']['BoundingBox']['Height'] * height\n",
    "            cropped = image.crop((start_x, start_y, end_x, end_y))\n",
    "            image_out = io.BytesIO()\n",
    "            cropped.save(image_out, 'JPEG')\n",
    "            cropped_faces.append(image_out.getvalue())\n",
    "        elif 'BoundingBox' in face:\n",
    "            start_x = face['BoundingBox']['Left'] * width\n",
    "            start_y = face['BoundingBox']['Top'] * height\n",
    "            end_x = start_x + face['BoundingBox']['Width'] * width\n",
    "            end_y = start_y + face['BoundingBox']['Height'] * height\n",
    "            cropped = image.crop((start_x, start_y, end_x, end_y))\n",
    "            image_out = io.BytesIO()\n",
    "            cropped.save(image_out, 'JPEG')\n",
    "            cropped_faces.append(image_out.getvalue())\n",
    "    return cropped_faces\n",
    "\n",
    "response = rekognition.compare_faces(SourceImage={'Bytes': source_image},\n",
    "                                     TargetImage={'Bytes': target_image}) # Set to zero to recover al faces.\n",
    "print('Face in the source image\\n')\n",
    "display(Image(data=crop_face(source_image, response['SourceImageFace'])))\n",
    "print('Matched faces\\n')\n",
    "for face in crop_faces(target_image, response['FaceMatches']):\n",
    "    display(Image(data=face))\n",
    "print('Unmatched faces\\n')\n",
    "for face in crop_faces(target_image, response['UnmatchedFaces']):\n",
    "    display(Image(data=face))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Detección de equipo protector\n",
    "\n",
    "En este laboratorio utilizaremos Rekognition para detectar equipo protector en imágenes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ppe_img_url = 'https://dhei5unw3vrsx.cloudfront.net/images/ppe_group_updated.jpg'\n",
    "ppe_image = requests.get(ppe_img_url, allow_redirects=True).content\n",
    "display(Image(data=ppe_image))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora realizaremos el análisis de la imagen y marcaremos el equipo detectado."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ppe_box(image_bytes, persons):\n",
    "    image = PImage.open(io.BytesIO(image_bytes))\n",
    "    width, height = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()\n",
    "    for person in persons:\n",
    "        for body_part in person['BodyParts']:\n",
    "            name = body_part['Name']\n",
    "            for equipment in body_part['EquipmentDetections']:\n",
    "                start_x = equipment['BoundingBox']['Left'] * width\n",
    "                start_y = equipment['BoundingBox']['Top'] * height\n",
    "                end_x = start_x + equipment['BoundingBox']['Width'] * width\n",
    "                end_y = start_y + equipment['BoundingBox']['Height'] * height\n",
    "                draw.rectangle([(start_x, start_y), (end_x, end_y)], outline='green', width=2)\n",
    "                draw.text((start_x + 5, start_y + 5), name + ' ' + equipment['Type'], fill='black', font=font)\n",
    "    image_out = io.BytesIO()\n",
    "    image.save(image_out, 'JPEG')\n",
    "    return image_out.getvalue()\n",
    "\n",
    "ppe_response = rekognition.detect_protective_equipment(Image={'Bytes': ppe_image})\n",
    "display(Image(data=ppe_box(ppe_image, ppe_response['Persons'])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}