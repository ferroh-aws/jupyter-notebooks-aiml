{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Laboratorio de Amazon Rekognition\n",
    "\n",
    "En este laboratorio exploraremos las siguientes capacidades de Rekognition.\n",
    "\n",
    "- Detección de Objetos y Escenas en imágenes.\n",
    "- Análisis Facial\n",
    "- Comparación de rostros\n",
    "- Detección de equipo protector\n",
    "\n",
    "En este laboratorio usaremos las siguientes librerías de Python.\n",
    "\n",
    "- SDK de AWS para Python - [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)\n",
    "- Python Requests - [requests](https://docs.python-requests.org/en/master/)\n",
    "- Python IO - [io](https://docs.python.org/3/library/io.html)\n",
    "- Jupyter IPython - [IPython](https://ipython.readthedocs.io/en/stable/)\n",
    "- Python Pillow - [PIL](https://pillow.readthedocs.io/en/stable/)\n",
    "\n",
    "*Tip: Durante los laboratorios es posible cambiar las URLs de las imagenes para experimentar con otros archivos.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de Objetos y Escenas\n",
    "\n",
    "En esta sección tomaremos diferentes imágenes y las analizaremos utilizando el servicio de Rekognition.\n",
    "\n",
    "Empezaremos por importar las librerías necesarias para la manipulación de imágenes y el cliente para utilizar Rekognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import requests\n",
    "import json\n",
    "import io\n",
    "from IPython.display import Image, display, JSON, Markdown, HTML\n",
    "from PIL import Image as PImage, ImageDraw, ImageFont\n",
    "\n",
    "# Se obtiene el cliente de Rekognition.\n",
    "rekognition = boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Esta función utilitaria nos servirá para crear rectángulos al rededor de los objetos detectados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def box_labels(image_bytes, labels, confidence):\n",
    "    font = ImageFont.load_default()\n",
    "    image = PImage.open(io.BytesIO(image_bytes))\n",
    "    width, height = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for label in labels:\n",
    "        name = label['Name']\n",
    "        if label['Confidence'] >= confidence:\n",
    "            for instance in label['Instances']:\n",
    "                if instance['Confidence'] >= confidence and 'BoundingBox' in instance:\n",
    "                    start_x = instance['BoundingBox']['Left'] * width\n",
    "                    start_y = instance['BoundingBox']['Top'] * height\n",
    "                    end_x = start_x + instance['BoundingBox']['Width'] * width\n",
    "                    end_y = start_y + instance['BoundingBox']['Height'] * height\n",
    "                    draw.rectangle([(start_x, start_y), (end_x, end_y)], outline='black', width=2)\n",
    "                    draw.text((start_x + 5, start_y + 5), name, fill='black', font=font)\n",
    "    image_out = io.BytesIO()\n",
    "    image.save(image_out, 'JPEG')\n",
    "    return image_out.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A continuación descargaremos las imágenes que serán utilizadas para detectar objetos y para detectar la escena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "objects_url = 'https://dhei5unw3vrsx.cloudfront.net/images/skateboard_resized.jpg'\n",
    "scene_url = 'https://dhei5unw3vrsx.cloudfront.net/images/landscape_resized.jpg'\n",
    "objects_response = requests.get(objects_url, allow_redirects=True)\n",
    "scene_response = requests.get(scene_url, allow_redirects=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ahora que contamos con las imágenes a analizar comencemos con la detección de objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "objects_image = objects_response.content\n",
    "display(Image(data=objects_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Rekognition cuenta con la funcionalidad de detección de etiquetas, para mayor detalles\n",
    "podemos visitar la sección de\n",
    " [detect_labels](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.detect_labels)\n",
    " en la documentación. En este caso enviaremos directamente los bytes de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "objects_a = rekognition.detect_labels(Image={\n",
    "    'Bytes': objects_image\n",
    "})\n",
    "display(Markdown(data='### Respuesta de Rekognition'))\n",
    "json_text = '''```\n",
    "{}\n",
    "```'''.format(json.dumps(objects_a, indent=2))\n",
    "display(Markdown(data=json_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Set a high confidence to reduce number of boxes.\n",
    "new_objects_image = box_labels(objects_image, objects_a['Labels'], 90.0)\n",
    "display(Markdown(data='### Imagen con objetos detectados'))\n",
    "display(Image(data=new_objects_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ahora analizaremos el contexto de la siguiente imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scene_image = scene_response.content\n",
    "display(Image(data=scene_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Utilizando el mismo servicio obtenemos el contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "objects_a = rekognition.detect_labels(Image={\n",
    "    'Bytes': scene_image\n",
    "})\n",
    "json_text = '''```\n",
    "{}\n",
    "```'''.format(json.dumps(objects_a, indent=2))\n",
    "display(Markdown(data=json_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 90.0\n",
    "html_text = '<table><tr><th>Etiqueta</th><th>Confianza</th></tr>'\n",
    "for label in objects_a['Labels']:\n",
    "    if label['Confidence'] >= confidence:\n",
    "        html_text += '<tr><td>{}</td><td>{}</td></tr>'.format(label['Name'], label['Confidence'])\n",
    "html_text += '</table>'\n",
    "display(HTML(data=html_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Análisis facial\n",
    "\n",
    "Ahora realizaremos un análisis facial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "single_face_url = 'https://dhei5unw3vrsx.cloudfront.net/images/drive_resized.jpg'\n",
    "multi_face_url = 'https://dhei5unw3vrsx.cloudfront.net/images/family_resized.jpg'\n",
    "single_face_image = requests.get(single_face_url, allow_redirects=True).content\n",
    "multi_face_image = requests.get(multi_face_url, allow_redirects=True).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definiremos las siguientes funciones para crear un cuadro donde Rekognition detecto el rostro e imprimir los detalles de cada rostro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "box_colors = ['red', 'green', 'blue', 'orange', 'yellow', 'black', 'grey', 'purple']\n",
    "\n",
    "def box_face(image_bytes, faces):\n",
    "    image = PImage.open(io.BytesIO(image_bytes))\n",
    "    width, height = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    idx = 0\n",
    "    for face in faces:\n",
    "        if 'BoundingBox' in face:\n",
    "            start_x = face['BoundingBox']['Left'] * width\n",
    "            start_y = face['BoundingBox']['Top'] * height\n",
    "            end_x = start_x + face['BoundingBox']['Width'] * width\n",
    "            end_y = start_y + face['BoundingBox']['Height'] * height\n",
    "            draw.rectangle([(start_x, start_y), (end_x, end_y)], outline=box_colors[idx], width=2)\n",
    "            idx = idx + 1 if idx + 1 < len(box_colors) else 0\n",
    "    image_out = io.BytesIO()\n",
    "    image.save(image_out, 'JPEG')\n",
    "    return image_out.getvalue()\n",
    "\n",
    "def features(faces, confidence):\n",
    "    idx = 0\n",
    "    markdown_text = ''\n",
    "    for face in faces:\n",
    "        markdown_text += '\\n#### Caja color ' + box_colors[idx]\n",
    "        markdown_text += '\\n Rango de edad entre {} y {}'.format(face['AgeRange']['Low'], face['AgeRange']['High'])\n",
    "        markdown_text += '\\n\\n| Característica | Valor | Confianza |'\n",
    "        markdown_text += '\\n| -------------- | ----- | --------- |'\n",
    "        markdown_text += '\\n| {} | {} | {} |'.format('Sonriendo', face['Smile']['Value'], face['Smile']['Confidence'])\n",
    "        markdown_text += '\\n| {} | {} | {} |'.format('Lentes', face['Eyeglasses']['Value'], face['Eyeglasses']['Confidence'])\n",
    "        markdown_text += '\\n| {} | {} | {} |'.format('Lentes de sol', face['Sunglasses']['Value'], face['Sunglasses']['Confidence'])\n",
    "        markdown_text += '\\n| {} | {} | {} |'.format('Sexo', face['Gender']['Value'], face['Gender']['Confidence'])\n",
    "        markdown_text += '\\n| {} | {} | {} |'.format('Barba', face['Beard']['Value'], face['Beard']['Confidence'])\n",
    "        markdown_text += '\\n| {} | {} | {} |'.format('Bigote', face['Mustache']['Value'], face['Mustache']['Confidence'])\n",
    "        markdown_text += '\\n| {} | {} | {} |'.format('Ojos abiertos', face['EyesOpen']['Value'], face['EyesOpen']['Confidence'])\n",
    "        markdown_text += '\\n| {} | {} | {} |'.format('Boca abierta', face['MouthOpen']['Value'], face['MouthOpen']['Confidence'])\n",
    "        for emotion in face['Emotions']:\n",
    "            if emotion['Confidence'] >= confidence:\n",
    "                markdown_text += '\\n\\nLa persona esta {}'.format(emotion['Type'])\n",
    "        idx = idx + 1 if idx + 1 < len(box_colors) else 0\n",
    "    return markdown_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "En este primer ejercicio utilizaremos una imagen con un solo rostros para el análisis.\n",
    "Para mayor información de los parámetros podemos visitar la sección de\n",
    " [detect_faces](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.detect_faces)\n",
    " en la documentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display(Image(data=single_face_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "detect_face_r = rekognition.detect_faces(Image={'Bytes': single_face_image}, Attributes=['ALL'])\n",
    "display(Image(data=box_face(single_face_image, detect_face_r['FaceDetails'])))\n",
    "display(Markdown(data=features(detect_face_r['FaceDetails'], 80.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ahora realicemos el análisis sobre una imagen con diferentes rostros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display(Image(data=multi_face_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "detect_face_r = rekognition.detect_faces(Image={'Bytes': multi_face_image}, Attributes=['ALL'])\n",
    "display(Image(data=box_face(multi_face_image, detect_face_r['FaceDetails'])))\n",
    "display(Markdown(data=features(detect_face_r['FaceDetails'], 80.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparación de Rostros\n",
    "\n",
    "En este laboratorio haremos una comparación de rostros entre dos imágenes con la finalidad de detectar si una persona se encuentra en ambas fotografías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "source_img_url = 'https://dhei5unw3vrsx.cloudfront.net/images/source3_resized.jpg'\n",
    "target_img_url = 'https://dhei5unw3vrsx.cloudfront.net/images/target3_resized.jpg'\n",
    "source_image = requests.get(source_img_url, allow_redirects=True).content\n",
    "target_image = requests.get(target_img_url, allow_redirects=True).content\n",
    "\n",
    "display(Image(data=source_image))\n",
    "display(Image(data=target_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definimos un par de funciones utilitarias para poder realizar un crop de las secciones de la imagen que contienen rostros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def crop_face(image_bytes, face):\n",
    "    image = PImage.open(io.BytesIO(image_bytes))\n",
    "    width, height = image.size\n",
    "    cropped_bytes = image_bytes\n",
    "    if 'BoundingBox' in face:\n",
    "        start_x = face['BoundingBox']['Left'] * width\n",
    "        start_y = face['BoundingBox']['Top'] * height\n",
    "        end_x = start_x + face['BoundingBox']['Width'] * width\n",
    "        end_y = start_y + face['BoundingBox']['Height'] * height\n",
    "        cropped = image.crop((start_x, start_y, end_x, end_y))\n",
    "        image_out = io.BytesIO()\n",
    "        cropped.save(image_out, 'JPEG')\n",
    "        cropped_bytes = image_out.getvalue()\n",
    "    return cropped_bytes\n",
    "\n",
    "def crop_faces(image_bytes, faces):\n",
    "    cropped_faces = list()\n",
    "    image = PImage.open(io.BytesIO(image_bytes))\n",
    "    width, height = image.size\n",
    "    for face in faces:\n",
    "        if 'Face' in face and 'BoundingBox' in face['Face']:\n",
    "            start_x = face['Face']['BoundingBox']['Left'] * width\n",
    "            start_y = face['Face']['BoundingBox']['Top'] * height\n",
    "            end_x = start_x + face['Face']['BoundingBox']['Width'] * width\n",
    "            end_y = start_y + face['Face']['BoundingBox']['Height'] * height\n",
    "            cropped = image.crop((start_x, start_y, end_x, end_y))\n",
    "            image_out = io.BytesIO()\n",
    "            cropped.save(image_out, 'JPEG')\n",
    "            cropped_faces.append(image_out.getvalue())\n",
    "        elif 'BoundingBox' in face:\n",
    "            start_x = face['BoundingBox']['Left'] * width\n",
    "            start_y = face['BoundingBox']['Top'] * height\n",
    "            end_x = start_x + face['BoundingBox']['Width'] * width\n",
    "            end_y = start_y + face['BoundingBox']['Height'] * height\n",
    "            cropped = image.crop((start_x, start_y, end_x, end_y))\n",
    "            image_out = io.BytesIO()\n",
    "            cropped.save(image_out, 'JPEG')\n",
    "            cropped_faces.append(image_out.getvalue())\n",
    "    return cropped_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realizamos el análisis con Rekognition, utilizaremos el servicio\n",
    " [compare_faces](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.compare_faces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "response = rekognition.compare_faces(SourceImage={'Bytes': source_image},\n",
    "                                     TargetImage={'Bytes': target_image}) # Set to zero to recover al faces.\n",
    "display(Markdown(data='### Rostro en la imagen origen'))\n",
    "display(Image(data=crop_face(source_image, response['SourceImageFace'])))\n",
    "display(Markdown(data='### Rostro localizado en la imagen destino'))\n",
    "for face in crop_faces(target_image, response['FaceMatches']):\n",
    "    display(Image(data=face))\n",
    "display(Markdown(data='### Rostros sin parecido en imagen destino'))\n",
    "for face in crop_faces(target_image, response['UnmatchedFaces']):\n",
    "    display(Image(data=face))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Detección de equipo protector\n",
    "\n",
    "En este laboratorio utilizaremos Rekognition para detectar equipo protector en imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppe_img_url = 'https://dhei5unw3vrsx.cloudfront.net/images/ppe_group_updated.jpg'\n",
    "ppe_image = requests.get(ppe_img_url, allow_redirects=True).content\n",
    "display(Image(data=ppe_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definiremos una función utilitaria para enmarcar el equipo protector detectado en la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ppe_box(image_bytes, persons):\n",
    "    image = PImage.open(io.BytesIO(image_bytes))\n",
    "    width, height = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()\n",
    "    for person in persons:\n",
    "        for body_part in person['BodyParts']:\n",
    "            name = body_part['Name']\n",
    "            for equipment in body_part['EquipmentDetections']:\n",
    "                start_x = equipment['BoundingBox']['Left'] * width\n",
    "                start_y = equipment['BoundingBox']['Top'] * height\n",
    "                end_x = start_x + equipment['BoundingBox']['Width'] * width\n",
    "                end_y = start_y + equipment['BoundingBox']['Height'] * height\n",
    "                draw.rectangle([(start_x, start_y), (end_x, end_y)], outline='yellow', width=2)\n",
    "                draw.text((start_x + 5, start_y + 5), name + ' ' + equipment['Type'], fill='black', font=font)\n",
    "    image_out = io.BytesIO()\n",
    "    image.save(image_out, 'JPEG')\n",
    "    return image_out.getvalue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realizaremos el análisis de la imagen y marcaremos el equipo detectado con el servicio\n",
    " [detect_protective_equipment](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.detect_protective_equipment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppe_response = rekognition.detect_protective_equipment(Image={'Bytes': ppe_image})\n",
    "display(Image(data=ppe_box(ppe_image, ppe_response['Persons'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}